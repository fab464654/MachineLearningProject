{"cells":[{"cell_type":"markdown","metadata":{"id":"gk6hmtxpIUh4"},"source":["# ResNet18 as a feature extractor\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bU-SKKhIIUiD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642776070708,"user_tz":-60,"elapsed":2503,"user":{"displayName":"Aaaa Aaaa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17206351073987113007"}},"outputId":"023fc084-96ef-4235-8626-7a0a573af0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Used device: cuda\n"]}],"source":["%matplotlib inline\n","\n","from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import pandas as pd\n","import sklearn\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, \\\n","    accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n","from IPython.display import clear_output\n","\n","plt.ion()   # interactive mode\n","\n","#Mounting Google Drive data\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","#Use GPU device\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Used device:\", device)"]},{"cell_type":"markdown","source":["ConvNet as fixed feature extractor\n"],"metadata":{"id":"oUT7F5DyqJYZ"}},{"cell_type":"markdown","source":["Feature vectors are extracted from the second last layer of the ResNet18 (vector of 512 elements)\n","\n","\n","\n","\n","The ResNet18 used is the pretrained one on ImageNet"],"metadata":{"id":"4gKtQE-mDL5s"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from PIL import Image\n","import csv\n","\n","from os import walk\n","\n","# Root directory of interest\n","gdrivePath = F\"gdrive/MyDrive/ML_AI\" # where to save accuracies, losses and model checkpoints (csv)\n","\n","# Dataset to use\n","data_dir = gdrivePath + \"/NatureDataset\"\n","\n","# Load the pretrained model\n","model = models.resnet18(pretrained=True) #github code was with ResNet18\n","\n","# Use the model object to select the desired layer\n","layer = model._modules.get('avgpool')\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Image transforms\n","scaler = transforms.Scale((224, 224))\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","to_tensor = transforms.ToTensor()\n","\n","def get_vector(image_name, classID):\n","    # 1. Load the image with Pillow library\n","    img = Image.open(image_name)\n","\n","    # 2. Create a PyTorch Variable with the transformed image\n","    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n"," \n","    # 3. Create a vector of zeros that will hold our feature vector\n","    #    The 'avgpool' layer has an output size of 512\n","    #my_embedding = torch.zeros(512)\n","    my_embedding = torch.zeros(1, 512, 1, 1) #CORRECTED ACCORDING TO: https://github.com/josharnoldjosh/Resnet-Extract-Image-Feature-Pytorch-Python/issues/1\n","\n","    # 4. Define a function that will copy the output of a layer\n","    def copy_data(m, i, o):\n","        my_embedding.copy_(o.data)\n","    # 5. Attach that function to our selected layer\n","    h = layer.register_forward_hook(copy_data)\n","    # 6. Run the model on our transformed image\n","    model(t_img)\n","    # 7. Detach our copy function from the layer\n","    h.remove()\n","    # 8. Return the feature vector\n","    #  for resnet18:\n","    feature_vector = my_embedding.numpy()[0, :, 0, 0] #TO RETRIEVE ONLY THE 512 ELEMENTS   \n","    \n","    feature_vector = np.insert(feature_vector, 0, classID)  #insert the class ID in the first position\n","    return feature_vector\n","\n","train_path = data_dir + \"/train\"\n","test_path = data_dir + \"/test\"\n","fv_list = []\n","\n","classes_dict = {\n","  \"buildings\": 0,\n","  \"forest\": 1,\n","  \"glacier\": 2,\n","  \"mountain\": 3,\n","  \"sea\": 4,\n","  \"street\": 5\n","}\n","\n","path_to_use = test_path\n","for (_, dirnames, filenames) in walk(path_to_use):\n","    dirnames = sorted(dirnames)\n","    for classDir in dirnames:\n","        classID = classes_dict[classDir] #retrieve the class id         \n","        print(\"Extracting features from \"+classDir+\"...\")\n","\n","        for (_, dirnames, filenames) in walk(path_to_use+\"/\"+classDir):\n","            \n","            #print(filenames)\n","            for fn in filenames:\n","                fv = get_vector(path_to_use + \"/\" + classDir + \"/\" + fn, classID)\n","                fv_list.append(fv)\n","    break\n","\n","#Write the feature vectors on a .csv file\n","with open('feature_vectors_test.csv', 'w') as f:      \n","    write = csv.writer(f)      \n","    write.writerows(fv_list)\n"],"metadata":{"id":"G9rt9shJqLXZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ResNet18_featureExtractor.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}